{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import requests\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_convert_files(taxi_type):\n",
    "    data_dir = Path(\"data\") / taxi_type\n",
    "    data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    for year in [2019, 2020]:\n",
    "        for month in range(1, 13):\n",
    "            parquet_filename = f\"{taxi_type}_tripdata_{year}-{month:02d}.parquet\"\n",
    "            parquet_filepath = data_dir / parquet_filename\n",
    "\n",
    "            if parquet_filepath.exists():\n",
    "                print(f\"Skipping {parquet_filename} (already exists)\")\n",
    "                continue\n",
    "\n",
    "            # Download CSV.gz file\n",
    "            csv_gz_filename = f\"{taxi_type}_tripdata_{year}-{month:02d}.csv.gz\"\n",
    "            csv_gz_filepath = data_dir / csv_gz_filename\n",
    "\n",
    "            response = requests.get(f\"{BASE_URL}/{taxi_type}/{csv_gz_filename}\", stream=True)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            with open(csv_gz_filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "            print(f\"Converting {csv_gz_filename} to Parquet...\")\n",
    "            con = duckdb.connect()\n",
    "            con.execute(f\"\"\"\n",
    "                COPY (SELECT * FROM read_csv_auto('{csv_gz_filepath}'))\n",
    "                TO '{parquet_filepath}' (FORMAT PARQUET)\n",
    "            \"\"\")\n",
    "            con.close()\n",
    "\n",
    "            # Remove the CSV.gz file to save space\n",
    "            csv_gz_filepath.unlink()\n",
    "            print(f\"Completed {parquet_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_gitignore():\n",
    "    gitignore_path = Path(\".gitignore\")\n",
    "\n",
    "    # Read existing content or start with empty string\n",
    "    content = gitignore_path.read_text() if gitignore_path.exists() else \"\"\n",
    "\n",
    "    # Add data/ if not already present\n",
    "    if 'data/' not in content:\n",
    "        with open(gitignore_path, 'a') as f:\n",
    "            f.write('\\n# Data directory\\ndata/\\n' if content else '# Data directory\\ndata/\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_gitignore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping yellow_tripdata_2019-01.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-02.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-03.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-04.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-05.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-06.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-07.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-08.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-09.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-10.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-11.parquet (already exists)\n",
      "Skipping yellow_tripdata_2019-12.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-01.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-02.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-03.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-04.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-05.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-06.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-07.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-08.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-09.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-10.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-11.parquet (already exists)\n",
      "Skipping yellow_tripdata_2020-12.parquet (already exists)\n",
      "Skipping green_tripdata_2019-01.parquet (already exists)\n",
      "Skipping green_tripdata_2019-02.parquet (already exists)\n",
      "Skipping green_tripdata_2019-03.parquet (already exists)\n",
      "Skipping green_tripdata_2019-04.parquet (already exists)\n",
      "Skipping green_tripdata_2019-05.parquet (already exists)\n",
      "Skipping green_tripdata_2019-06.parquet (already exists)\n",
      "Skipping green_tripdata_2019-07.parquet (already exists)\n",
      "Skipping green_tripdata_2019-08.parquet (already exists)\n",
      "Skipping green_tripdata_2019-09.parquet (already exists)\n",
      "Skipping green_tripdata_2019-10.parquet (already exists)\n",
      "Skipping green_tripdata_2019-11.parquet (already exists)\n",
      "Skipping green_tripdata_2019-12.parquet (already exists)\n",
      "Skipping green_tripdata_2020-01.parquet (already exists)\n",
      "Skipping green_tripdata_2020-02.parquet (already exists)\n",
      "Skipping green_tripdata_2020-03.parquet (already exists)\n",
      "Skipping green_tripdata_2020-04.parquet (already exists)\n",
      "Skipping green_tripdata_2020-05.parquet (already exists)\n",
      "Skipping green_tripdata_2020-06.parquet (already exists)\n",
      "Skipping green_tripdata_2020-07.parquet (already exists)\n",
      "Skipping green_tripdata_2020-08.parquet (already exists)\n",
      "Skipping green_tripdata_2020-09.parquet (already exists)\n",
      "Skipping green_tripdata_2020-10.parquet (already exists)\n",
      "Skipping green_tripdata_2020-11.parquet (already exists)\n",
      "Skipping green_tripdata_2020-12.parquet (already exists)\n"
     ]
    }
   ],
   "source": [
    "for taxi_type in [\"yellow\", \"green\"]:\n",
    "        download_and_convert_files(taxi_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x107e4f9b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect(\"taxi_rides_ny/taxi_rides_ny.duckdb\")\n",
    "con.execute(\"CREATE SCHEMA IF NOT EXISTS prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e14820bbc84d45b6e757967c5a3b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for taxi_type in [\"yellow\", \"green\"]:\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE OR REPLACE TABLE prod.{taxi_type}_tripdata AS\n",
    "            SELECT * FROM read_parquet('data/{taxi_type}/*.parquet', union_by_name=true)\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
